{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一个小目标 mission three\n",
    "---\n",
    "\n",
    "\n",
    "## 任务\n",
    "分别使用 xgboost 与 lightgbm 对客户逾期情况进行建模，预测用户是否会逾期\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导入需要的包\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, f1_score, classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 设置 pandas 显示列数\n",
    "pd.set_option('display.max_columns', 10000)\n",
    "pd.set_option('display.width', 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 因为数据并非utf-8编码，要使用gbk编码读入，否则出错\n",
    "data = pd.read_csv('./data/data.csv', index_col=0, encoding='gbk')\n",
    "\n",
    "# 观察数据构成\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (4754, 88)\n",
      "y 的分布\n",
      " 0    3561\n",
      "1    1193\n",
      "Name: status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 划分 X, y\n",
    "y = data['status']\n",
    "X = data.drop('status', axis=1)\n",
    "\n",
    "# X行数\n",
    "print('X.shape:', X.shape)\n",
    "print('y 的分布\\n', y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据探索及特征处理\n",
    "本次任务目的在于主流程，所以数据探索部分做得比较粗糙，以后有需要再慢慢补充\n",
    "从上面数据看出，本份数据以数值型特征位数，有少数几个字符型特征，还有两个日期特征。下面一步步进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4754, 85)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 首先剔除一些明显无用的特征，如 id_name, custid, trade_no, bank_card_no，\n",
    "# 这些优点类似一个人的唯一信息，如果加入模型训练且对最终模型生效的话，很可能就是出现了过拟合\n",
    "X.drop(['id_name', 'custid', 'trade_no', 'bank_card_no'], axis=1, inplace=True)\n",
    "\n",
    "# 数值型变量\n",
    "X_num = X.select_dtypes('number').copy()\n",
    "# student_feature\n",
    "X_num.fillna({'student_feature': 0}, inplace=True)\n",
    "# 其他数值型变量使用均值代替\n",
    "X_num.fillna(X_num.mean(), inplace=True)\n",
    "\n",
    "# 字符型变量\n",
    "X_str = X.select_dtypes(exclude='number').copy()\n",
    "X_str_dummy = pd.get_dummies(X_str['reg_preference_for_trad'])\n",
    "\n",
    "# 合并\n",
    "X_cl = pd.concat([X_num, X_str_dummy], axis=1, sort=False)\n",
    "X_cl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 数据划分\n",
    "三七 分，随机种子就取今天日期吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3327, 85)\n",
      "(1427, 85)\n"
     ]
    }
   ],
   "source": [
    "random_state = 1115\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cl, y, test_size=0.3, random_state=random_state)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 数据归一化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "X_train_std = ss.fit_transform(X_train)\n",
    "X_test_std = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 建模\n",
    "#### model1-LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.05, 'penalty': 'l1'}\n",
      "0.793808235648\n"
     ]
    }
   ],
   "source": [
    "# 先用网格搜索选下超参，\n",
    "# 评价参数没有给出，这次使用 f1_micro 作为评价标准\n",
    "lr = LogisticRegression()\n",
    "param_grid = {\n",
    "    'C': [0.05, 0.1, 0.5, 1, 5],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(lr, param_grid=param_grid, scoring='f1_micro')\n",
    "\n",
    "grid.fit(X_train_std, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确性：\n",
      "Train：0.7986\n",
      "Test：0.8031\n",
      "f1_score：\n",
      "Train：0.4444\n",
      "Test：0.4565\n"
     ]
    }
   ],
   "source": [
    "# 使用训练好的超参进行建模\n",
    "lr = LogisticRegression(**grid.best_params_)\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "# 准确性\n",
    "y_train_pred = lr.predict(X_train_std)\n",
    "y_test_pred = lr.predict(X_test_std)\n",
    "print('准确性：')\n",
    "print('Train：{:.4f}'.format(accuracy_score(y_train, y_train_pred)))\n",
    "print('Test：{:.4f}'.format(accuracy_score(y_test, y_test_pred)))\n",
    "# f1_score\n",
    "print('f1_score：')\n",
    "print('Train：{:.4f}'.format(f1_score(y_train, y_train_pred)))\n",
    "print('Test：{:.4f}'.format(f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model2-svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确性：\n",
      "Train：0.7977\n",
      "Test：0.8031\n",
      "f1_score：\n",
      "Train：0.4524\n",
      "Test：0.4586\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "# 线性 SVM\n",
    "lsvc = LinearSVC()\n",
    "lsvc.fit(X_train_std, y_train)\n",
    "\n",
    "# 准确性\n",
    "y_train_pred = lsvc.predict(X_train_std)\n",
    "y_test_pred = lsvc.predict(X_test_std)\n",
    "print('准确性：')\n",
    "print('Train：{:.4f}'.format(accuracy_score(y_train, y_train_pred)))\n",
    "print('Test：{:.4f}'.format(accuracy_score(y_test, y_test_pred)))\n",
    "# f1_score\n",
    "print('f1_score：')\n",
    "print('Train：{:.4f}'.format(f1_score(y_train, y_train_pred)))\n",
    "print('Test：{:.4f}'.format(f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确性：\n",
      "Train：0.8323\n",
      "Test：0.7996\n",
      "f1_score：\n",
      "Train：0.5295\n",
      "Test：0.4066\n"
     ]
    }
   ],
   "source": [
    "# 非线性 SVM\n",
    "svc = SVC()\n",
    "svc.fit(X_train_std, y_train)\n",
    "\n",
    "# 准确性\n",
    "y_train_pred = svc.predict(X_train_std)\n",
    "y_test_pred = svc.predict(X_test_std)\n",
    "print('准确性：')\n",
    "print('Train：{:.4f}'.format(accuracy_score(y_train, y_train_pred)))\n",
    "print('Test：{:.4f}'.format(accuracy_score(y_test, y_test_pred)))\n",
    "# f1_score\n",
    "print('f1_score：')\n",
    "print('Train：{:.4f}'.format(f1_score(y_train, y_train_pred)))\n",
    "print('Test：{:.4f}'.format(f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model3-决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确性：\n",
      "Train：1.0000\n",
      "Test：0.7043\n",
      "f1_score：\n",
      "Train：1.0000\n",
      "Test：0.4139\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# 决策树\n",
    "# 线性 SVM\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train_std, y_train)\n",
    "\n",
    "# 准确性\n",
    "y_train_pred = dt.predict(X_train_std)\n",
    "y_test_pred = dt.predict(X_test_std)\n",
    "print('准确性：')\n",
    "print('Train：{:.4f}'.format(accuracy_score(y_train, y_train_pred)))\n",
    "print('Test：{:.4f}'.format(accuracy_score(y_test, y_test_pred)))\n",
    "# f1_score\n",
    "print('f1_score：')\n",
    "print('Train：{:.4f}'.format(f1_score(y_train, y_train_pred)))\n",
    "print('Test：{:.4f}'.format(f1_score(y_test, y_test_pred)))\n",
    "\n",
    "# 这里其实有点过拟合了，在训练集上的预测是 100%。但是这点暂时不处理，以后调参的时候再进行研究"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model4-XGBoost\n",
    "\n",
    "**安装**\n",
    "\n",
    "安装包路径：https://www.lfd.uci.edu/~gohlke/pythonlibs/#xgboost\n",
    "\n",
    "找到合适的包，使用pip安装。如 pip install xgboost-0.81-cp27-cp27m-win_amd64.whl\n",
    "\n",
    "**使用**\n",
    "\n",
    "下面所说仅仅是普通调用，然而 XGB 有很多超参数需要调整，而且这些超参对结果会产生很大的影响，这次先不展开阐述。\n",
    "\n",
    "参考：[XGBoost使用教程（纯xgboost方法）](https://blog.csdn.net/u011630575/article/details/79418138)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-auc-mean</th>\n",
       "      <th>train-auc-std</th>\n",
       "      <th>test-auc-mean</th>\n",
       "      <th>test-auc-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.786727</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.711017</td>\n",
       "      <td>0.016283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.820915</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>0.733160</td>\n",
       "      <td>0.021281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.837428</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>0.738238</td>\n",
       "      <td>0.022022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.852458</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>0.747465</td>\n",
       "      <td>0.018232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.860994</td>\n",
       "      <td>0.004971</td>\n",
       "      <td>0.747937</td>\n",
       "      <td>0.018504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.866400</td>\n",
       "      <td>0.004904</td>\n",
       "      <td>0.754532</td>\n",
       "      <td>0.017471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.871660</td>\n",
       "      <td>0.004822</td>\n",
       "      <td>0.757910</td>\n",
       "      <td>0.013978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.876657</td>\n",
       "      <td>0.004699</td>\n",
       "      <td>0.762000</td>\n",
       "      <td>0.014110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.882297</td>\n",
       "      <td>0.005793</td>\n",
       "      <td>0.762960</td>\n",
       "      <td>0.015213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.886179</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.764889</td>\n",
       "      <td>0.016537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.890028</td>\n",
       "      <td>0.004406</td>\n",
       "      <td>0.766328</td>\n",
       "      <td>0.017272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.894911</td>\n",
       "      <td>0.003916</td>\n",
       "      <td>0.768042</td>\n",
       "      <td>0.017381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.898845</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.769913</td>\n",
       "      <td>0.016838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.902277</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>0.771919</td>\n",
       "      <td>0.017189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.905154</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.772619</td>\n",
       "      <td>0.018172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.908487</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.772524</td>\n",
       "      <td>0.018328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.911507</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.774379</td>\n",
       "      <td>0.017927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.914692</td>\n",
       "      <td>0.003859</td>\n",
       "      <td>0.774816</td>\n",
       "      <td>0.018993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.917837</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.774767</td>\n",
       "      <td>0.018570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.920322</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.775106</td>\n",
       "      <td>0.017373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.923999</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>0.776541</td>\n",
       "      <td>0.017327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.925301</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.776747</td>\n",
       "      <td>0.017342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.928312</td>\n",
       "      <td>0.002560</td>\n",
       "      <td>0.776554</td>\n",
       "      <td>0.015788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.930775</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>0.776423</td>\n",
       "      <td>0.014376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.933397</td>\n",
       "      <td>0.003568</td>\n",
       "      <td>0.777060</td>\n",
       "      <td>0.013781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.935911</td>\n",
       "      <td>0.003493</td>\n",
       "      <td>0.778579</td>\n",
       "      <td>0.015246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.938390</td>\n",
       "      <td>0.003677</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.014306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.940830</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.780033</td>\n",
       "      <td>0.015559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.942624</td>\n",
       "      <td>0.003550</td>\n",
       "      <td>0.779981</td>\n",
       "      <td>0.015471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.944154</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>0.780326</td>\n",
       "      <td>0.015748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.946581</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.780269</td>\n",
       "      <td>0.016410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.948458</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>0.780914</td>\n",
       "      <td>0.017213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.950130</td>\n",
       "      <td>0.003589</td>\n",
       "      <td>0.781069</td>\n",
       "      <td>0.017911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.952111</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0.781200</td>\n",
       "      <td>0.017464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.954162</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.782408</td>\n",
       "      <td>0.017656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.955424</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>0.782159</td>\n",
       "      <td>0.017101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.956918</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>0.782678</td>\n",
       "      <td>0.017883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.958907</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>0.782932</td>\n",
       "      <td>0.018749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.959899</td>\n",
       "      <td>0.003095</td>\n",
       "      <td>0.782772</td>\n",
       "      <td>0.018872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.961886</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>0.783112</td>\n",
       "      <td>0.018332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.963724</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.782901</td>\n",
       "      <td>0.018727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.964708</td>\n",
       "      <td>0.002898</td>\n",
       "      <td>0.783330</td>\n",
       "      <td>0.019669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
       "0         0.786727       0.006035       0.711017      0.016283\n",
       "1         0.820915       0.005441       0.733160      0.021281\n",
       "2         0.837428       0.003187       0.738238      0.022022\n",
       "3         0.852458       0.003771       0.747465      0.018232\n",
       "4         0.860994       0.004971       0.747937      0.018504\n",
       "5         0.866400       0.004904       0.754532      0.017471\n",
       "6         0.871660       0.004822       0.757910      0.013978\n",
       "7         0.876657       0.004699       0.762000      0.014110\n",
       "8         0.882297       0.005793       0.762960      0.015213\n",
       "9         0.886179       0.004136       0.764889      0.016537\n",
       "10        0.890028       0.004406       0.766328      0.017272\n",
       "11        0.894911       0.003916       0.768042      0.017381\n",
       "12        0.898845       0.002683       0.769913      0.016838\n",
       "13        0.902277       0.002177       0.771919      0.017189\n",
       "14        0.905154       0.002479       0.772619      0.018172\n",
       "15        0.908487       0.002094       0.772524      0.018328\n",
       "16        0.911507       0.002709       0.774379      0.017927\n",
       "17        0.914692       0.003859       0.774816      0.018993\n",
       "18        0.917837       0.003393       0.774767      0.018570\n",
       "19        0.920322       0.002852       0.775106      0.017373\n",
       "20        0.923999       0.002153       0.776541      0.017327\n",
       "21        0.925301       0.002059       0.776747      0.017342\n",
       "22        0.928312       0.002560       0.776554      0.015788\n",
       "23        0.930775       0.003019       0.776423      0.014376\n",
       "24        0.933397       0.003568       0.777060      0.013781\n",
       "25        0.935911       0.003493       0.778579      0.015246\n",
       "26        0.938390       0.003677       0.779789      0.014306\n",
       "27        0.940830       0.003511       0.780033      0.015559\n",
       "28        0.942624       0.003550       0.779981      0.015471\n",
       "29        0.944154       0.003159       0.780326      0.015748\n",
       "30        0.946581       0.002847       0.780269      0.016410\n",
       "31        0.948458       0.003642       0.780914      0.017213\n",
       "32        0.950130       0.003589       0.781069      0.017911\n",
       "33        0.952111       0.003532       0.781200      0.017464\n",
       "34        0.954162       0.003132       0.782408      0.017656\n",
       "35        0.955424       0.003288       0.782159      0.017101\n",
       "36        0.956918       0.003425       0.782678      0.017883\n",
       "37        0.958907       0.003451       0.782932      0.018749\n",
       "38        0.959899       0.003095       0.782772      0.018872\n",
       "39        0.961886       0.002864       0.783112      0.018332\n",
       "40        0.963724       0.002690       0.782901      0.018727\n",
       "41        0.964708       0.002898       0.783330      0.019669"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 xgbboost 原生的模型调用\n",
    "import xgboost as xgb\n",
    "\n",
    "# 定义样本\n",
    "dtrain = xgb.DMatrix(X_train_std, label=y_train)\n",
    "# 定义 xgb 参数\n",
    "xgb_params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 1000,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 0,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': 4,\n",
    "    'scale_pos_weight': 1,\n",
    "    'seed': 112\n",
    "}\n",
    "# 通过交叉验证寻找最优迭代次数\n",
    "cvresult = xgb.cv(xgb_params, dtrain, \n",
    "                  num_boost_round=1000,  # 最大迭代次数\n",
    "                  nfold=5,  # n 折交叉检验\n",
    "                  metrics='auc',  # 评价指标\n",
    "                  early_stopping_rounds=30,  # 早停，如果n轮后效果均没有提升，则停止\n",
    "                  verbose_eval=False,  # 打印日志\n",
    "                 )\n",
    "xgb_params.update(n_estimators=cvresult.shape[0])  # 结果行数 即 最优迭代次数\n",
    "cvresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确性：\n",
      "Train：0.8798\n",
      "Test：0.7940\n",
      "f1_score：\n",
      "Train：0.7028\n",
      "Test：0.4712\n"
     ]
    }
   ],
   "source": [
    "# 重新训练模型（这里一定要给出迭代次数）\n",
    "xgb_model1 = xgb.train(xgb_params, xgb_train, num_boost_round=xgb_params['n_estimators'])\n",
    "# 预测出来的是第一类的数量，注意，这里传入的数据也需要通过 Dmatrix 转换，否则报错\n",
    "y_train_pred_proba = xgb_model1.predict(xgb.DMatrix(X_train_std))\n",
    "y_test_pred_proba = xgb_model1.predict(xgb.DMatrix(X_test_std))\n",
    "# 转换成分类\n",
    "y_train_pred = (y_train_pred_proba >= 0.5) + 0\n",
    "y_test_pred = (y_test_pred_proba >= 0.5) + 0\n",
    "\n",
    "# 评估\n",
    "# 准确性\n",
    "print('准确性：')\n",
    "print('Train：{:.4f}'.format(accuracy_score(y_train, y_train_pred)))\n",
    "print('Test：{:.4f}'.format(accuracy_score(y_test, y_test_pred)))\n",
    "# f1_score\n",
    "print('f1_score：')\n",
    "print('Train：{:.4f}'.format(f1_score(y_train, y_train_pred)))\n",
    "print('Test：{:.4f}'.format(f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=5, min_child_weight=1, missing=None, n_estimators=42,\n",
      "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=112,\n",
      "       silent=True, subsample=0.8)\n",
      "准确性：\n",
      "Train：0.8798\n",
      "Test：0.7940\n",
      "f1_score：\n",
      "Train：0.7028\n",
      "Test：0.4712\n"
     ]
    }
   ],
   "source": [
    "# xgbboost 对于sklearn的支持，调用起来更加方便\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "xgb_model2 = XGBClassifier(**xgb_params) # 迭代次数(n_estimators)已经是超参之一\n",
    "print(xgb_model2)\n",
    "\n",
    "# 训练\n",
    "xgb_model2.fit(X_train_std, y_train)\n",
    "# 预测\n",
    "y_train_pred = xgb_model2.predict(X_train_std)\n",
    "y_test_pred = xgb_model2.predict(X_test_std)\n",
    "\n",
    "# 评估\n",
    "# 准确性\n",
    "print('准确性：')\n",
    "print('Train：{:.4f}'.format(accuracy_score(y_train, y_train_pred)))\n",
    "print('Test：{:.4f}'.format(accuracy_score(y_test, y_test_pred)))\n",
    "# f1_score\n",
    "print('f1_score：')\n",
    "print('Train：{:.4f}'.format(f1_score(y_train, y_train_pred)))\n",
    "print('Test：{:.4f}'.format(f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里需要注意的是，两个不同调用方法在具体使用上略有差异，使用需要留意"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model5-LightGBM\n",
    "\n",
    "**安装**\n",
    "\n",
    "使用 pip install lightgbm 直接安装\n",
    "\n",
    "**使用**\n",
    "\n",
    "这里的用法与xgb的非常类似\n",
    "\n",
    "参考：[【集成学习】lightgbm使用案例](https://www.cnblogs.com/wanglei5205/p/8654041.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确性：\n",
      "Train：0.8843\n",
      "Test：0.7996\n",
      "f1_score：\n",
      "Train：0.7154\n",
      "Test：0.4743\n"
     ]
    }
   ],
   "source": [
    "# 使用 lightgbm 原生的模型调用\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_params  = {\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 42,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 0,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'objective': 'binary', # 这里和 xgb 不一样\n",
    "    'nthread': 4,\n",
    "    'scale_pos_weight': 1,\n",
    "    'seed': 112\n",
    "}\n",
    "\n",
    "dtrain = lgb.Dataset(X_train_std, y_train)\n",
    "\n",
    "# 重新训练模型（这里一定要给出迭代次数）\n",
    "lgb_model1 = lgb.train(lgb_params, lgb_train, num_boost_round=xgb_params['n_estimators'])\n",
    "# 预测出来的是第一类的数量，这里预测的时候只需要传入原数据就可以，不用转换成 Dataset，否则报错\n",
    "y_train_pred_proba = lgb_model1.predict(X_train_std)\n",
    "y_test_pred_proba = lgb_model1.predict(X_test_std)\n",
    "# 转换成分类\n",
    "y_train_pred = (y_train_pred_proba >= 0.5) + 0\n",
    "y_test_pred = (y_test_pred_proba >= 0.5) + 0\n",
    "\n",
    "# 评估\n",
    "# 准确性\n",
    "print('准确性：')\n",
    "print('Train：{:.4f}'.format(accuracy_score(y_train, y_train_pred)))\n",
    "print('Test：{:.4f}'.format(accuracy_score(y_test, y_test_pred)))\n",
    "# f1_score\n",
    "print('f1_score：')\n",
    "print('Train：{:.4f}'.format(f1_score(y_train, y_train_pred)))\n",
    "print('Test：{:.4f}'.format(f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,\n",
      "        gamma=0, importance_type='split', learning_rate=0.1, max_depth=5,\n",
      "        min_child_samples=20, min_child_weight=1, min_split_gain=0.0,\n",
      "        n_estimators=42, n_jobs=-1, nthread=4, num_leaves=31,\n",
      "        objective='binary', random_state=None, reg_alpha=0.0,\n",
      "        reg_lambda=0.0, scale_pos_weight=1, seed=112, silent=True,\n",
      "        subsample=0.8, subsample_for_bin=200000, subsample_freq=0)\n",
      "准确性：\n",
      "Train：0.8843\n",
      "Test：0.7996\n",
      "f1_score：\n",
      "Train：0.7154\n",
      "Test：0.4743\n"
     ]
    }
   ],
   "source": [
    "# 同理，lightgbm 也有对于sklearn的支持\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "lgb_model2 = LGBMClassifier(**lgb_params) # 迭代次数(n_estimators)已经是超参之一\n",
    "print(lgb_model2)\n",
    "\n",
    "# 训练\n",
    "lgb_model2.fit(X_train_std, y_train)\n",
    "# 预测\n",
    "y_train_pred = lgb_model2.predict(X_train_std)\n",
    "y_test_pred = lgb_model2.predict(X_test_std)\n",
    "\n",
    "# 评估\n",
    "# 准确性\n",
    "print('准确性：')\n",
    "print('Train：{:.4f}'.format(accuracy_score(y_train, y_train_pred)))\n",
    "print('Test：{:.4f}'.format(accuracy_score(y_test, y_test_pred)))\n",
    "# f1_score\n",
    "print('f1_score：')\n",
    "print('Train：{:.4f}'.format(f1_score(y_train, y_train_pred)))\n",
    "print('Test：{:.4f}'.format(f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}